const e=`Societal gender biases are widely reflected in media, which is used to train large language models (LLMs)**. Because the training data of LLMs contains societal biases, the model learns to reflect this bias**[^1]. As LLMs become increasingly integrated into automatic-decision making systems, this causes harm to women and other gender minorities. This is an open area of research, as LLMs are resilient to alignment techniques and vulnerable to jailbreaking[^2]. 

[^1]:  Garg, *Word Embeddings* 

[^2]:  Hoffman, *AI Generates Covertly Racist Decisions*; Yi, *Jailbreak Attacks*`;export{e as default};
