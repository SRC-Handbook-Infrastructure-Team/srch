const e=`There are two unique ways that representation bias in AI is different from representation bias in other fields. 

1. Metadata is often not collected during the data generation process. Without this information, it is difficult to measure underrepresentation in a dataset.   
2. Without rigorous intersectional evaluation after model development, it is impossible to know how much a model is impacted by representation bias. 

In the private sector, profit incentives to minimize development costs can lead to datasets developed without metadata and models that are released before intersectional evaluation is completed. Representation related harms can be measured in academic research (e.g. “Gender Shades”[^1]) and regulated via governance structures. For more information on AI governance \\[nav:check out this primer\\](governance).    


[^1]:  Buolamwini, “Gender Shades”`;export{e as default};
